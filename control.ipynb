{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "from seaborn_analyzer import regplot\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import japanize_matplotlib\n",
    "import random\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')\n",
    "from openpyxl import load_workbook\n",
    "from datetime import datetime, timedelta\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "from platypus import NSGAIII, Problem, Real, Constraint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作成した予測モデルを目的関数にもつNSGA-IIIアルゴリズムによる非線形最適化問題で計画自動生成プログラム"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 便利関数群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_dump(obj, path):\n",
    "    with open(path, mode='wb') as f:\n",
    "        pickle.dump(obj,f)\n",
    "\n",
    "def pickle_load(path):\n",
    "    with open(path, mode='rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        return data\n",
    "\n",
    "def validate_input(target_to_features, data):\n",
    "    \"\"\"\n",
    "    入力変数とデータ構造を検証します。\n",
    "    Args:\n",
    "        target_to_features (dict): 目的変数と対応する説明変数のディクショナリ。\n",
    "        data (pd.DataFrame): 入力データ。\n",
    "    Raises:\n",
    "        ValueError: 入力が無効な場合。\n",
    "    \"\"\"\n",
    "    if not isinstance(target_to_features, dict):\n",
    "        raise ValueError(\"target_to_features must be a dictionary\")\n",
    "    for target, features in target_to_features.items():\n",
    "        if not isinstance(target, str) or not isinstance(features, list):\n",
    "            raise ValueError(\"target_to_features keys must be strings and values must be lists\")\n",
    "        if target not in data.columns:\n",
    "            raise ValueError(f\"{target} is not a column in the data\")\n",
    "        for feature in features:\n",
    "            if feature not in data.columns:\n",
    "                raise ValueError(f\"{feature} is not a column in the data\")\n",
    "\n",
    "def create_directory_if_not_exists(directory_path):\n",
    "    \"\"\"\n",
    "    指定されたパスにフォルダが存在しない場合、フォルダを作成します。\n",
    "    Args:\n",
    "        directory_path (str): フォルダを作成するパス。\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "\n",
    "def check_file_path(file_path):\n",
    "    \"\"\"\n",
    "    指定されたパスにフォルダが存在しない場合、エラーを返します。\n",
    "    Args:\n",
    "        directory_path (str): フォルダを作成するパス。\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "def add_hour_column(df):\n",
    "    \"\"\"\n",
    "    'time'列から時刻を抽出し、新しい列としてDataFrameに追加します。\n",
    "    Args:\n",
    "        df (pd.DataFrame): 入力データ。\n",
    "    Returns:\n",
    "        pd.DataFrame: 新しい 'hour' 列が追加されたDataFrame。\n",
    "    \"\"\"\n",
    "    df['hour'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.hour\n",
    "    return df\n",
    "\n",
    "def one_hot_encode_hours(df):\n",
    "    \"\"\"\n",
    "    'hour' 列をワンホットエンコードし、変更されたDataFrameを返します。\n",
    "    Args:\n",
    "        df (pd.DataFrame): 入力データ。\n",
    "    Returns:\n",
    "        pd.DataFrame: ワンホットエンコードされた 'hour' 列を持つDataFrame。\n",
    "    \"\"\"\n",
    "    all_hours = range(1, 24)\n",
    "    hour_columns = [f'hour_{h}' for h in all_hours]\n",
    "    df = pd.get_dummies(df, columns=['hour'], prefix='hour', drop_first=True)\n",
    "    # 全てのhour列が含まれるように、存在しない列を追加する\n",
    "    for col in hour_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_actual_vs_predicted_and_residuals(train_df, test_df, target, features, train_y_pred, test_y_pred, residuals, save_directory, eval_metric):\n",
    "    \"\"\"\n",
    "    実際の値と予測値のグラフおよび残差グラフをプロットし、保存する関数。\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): 学習用データセット。\n",
    "        test_df (pd.DataFrame): 検証用データセット。\n",
    "        target (str): 目的変数。\n",
    "        features (list): 説明変数のリスト。\n",
    "        train_y_pred (np.array): 学習用データの予測値。\n",
    "        test_y_pred (np.array): 検証用データの予測値。\n",
    "        residuals (np.array): 学習用データの残差。\n",
    "        save_directory (str): 結果を保存するディレクトリへのパス。\n",
    "        eval_metric (str): 評価指標。\n",
    "    \"\"\"\n",
    "    # 観測値、予測値 vs. time\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(50, 16))\n",
    "    axs[0].plot(train_df['time'], train_df[target], label='Actual')\n",
    "    axs[0].plot(train_df['time'], train_y_pred, label='Predicted')\n",
    "    axs[0].set_title('Train Data')\n",
    "    axs[0].set_xlabel('Time')\n",
    "    axs[0].set_ylabel(target)\n",
    "    axs[0].legend()\n",
    "    \n",
    "    axs[1].plot(test_df['time'], test_df[target], label='Actual')\n",
    "    axs[1].plot(test_df['time'], test_y_pred, label='Predicted')\n",
    "    axs[1].set_title('Test Data')\n",
    "    axs[1].set_xlabel('Time')\n",
    "    axs[1].set_ylabel(target)\n",
    "    axs[1].legend()\n",
    "    \n",
    "    fig.suptitle(f'{target} - Actual vs Predicted')\n",
    "    plt.savefig(os.path.join(save_directory, f'{target}_yy_vs_time_{eval_metric}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "    # 残差 vs. 説明変数\n",
    "    fig, ax = plt.subplots(1, len(features), figsize=(10*len(features), 20))\n",
    "    for i in range(len(features)):\n",
    "        if len(features) > 1:\n",
    "            ax[i].scatter(train_df[features[i]], residuals)\n",
    "            ax[i].set_xlabel(features[i])\n",
    "            ax[i].set_ylabel('Residuals')\n",
    "        else:\n",
    "            ax.scatter(train_df[features[i]], residuals)\n",
    "            ax.set_xlabel(features[i])\n",
    "            ax.set_ylabel('Residuals')\n",
    "    plt.savefig(os.path.join(save_directory,f'{target}_residuals_vs_xvars_{eval_metric}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "def predict_and_evaluate(models:dict, df:pd.DataFrame, target_to_features:dict, save_path:str):\n",
    "    \"\"\"\n",
    "    与えられたモデルを使って、指定されたDataFrameに対して予測を行い、各種評価指標とグラフを表示します。\n",
    "    Args:\n",
    "        models (dict): ターゲット変数ごとに訓練されたモデルの辞書\n",
    "        df (pd.DataFrame): 予測を行う対象のデータフレーム\n",
    "        target_to_features (dict): ターゲット変数ごとに使用する説明変数のリストを格納した辞書, 説明変数にはOne Hot Encodingされて生成された時間列含む。\n",
    "        save_path (str): グラフを保存するディレクトリのパス\n",
    "    \"\"\"\n",
    "    # 時間（Hour）列を作成\n",
    "    df = add_hour_column(df)\n",
    "    \n",
    "    # 時間列に対してOne Hot Encodingを実行\n",
    "    df = one_hot_encode_hours(df)\n",
    "\n",
    "    # 結果を格納するDataFrameを作成\n",
    "    result_df = pd.DataFrame(columns=['y_var', 'mse', 'mae', 'r2'])\n",
    "\n",
    "    for target, features in target_to_features.items():\n",
    "        # 予測値を計算\n",
    "        y_pred = models[target].predict(df[features])\n",
    "\n",
    "        # 評価指標を計算\n",
    "        mse = mean_squared_error(df[target], y_pred)\n",
    "        mae = mean_absolute_error(df[target], y_pred)\n",
    "        r2 = r2_score(df[target], y_pred)\n",
    "\n",
    "        # 結果をDataFrameに追加\n",
    "        result_df.loc[len(result_df)] = [target, mse, mae, r2]\n",
    "\n",
    "        # グラフの作成\n",
    "        fig, ax = plt.subplots(figsize=(15, 6))\n",
    "        ax.plot(df['time'], df[target], label='Actual')\n",
    "        ax.plot(df['time'], y_pred, label='Predicted')\n",
    "        ax.set_title(f'{target} - Actual vs Predicted')\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel(target)\n",
    "        ax.legend()\n",
    "\n",
    "        # グラフの保存\n",
    "        plt.savefig(os.path.join(save_path, f'{target}_prediction.png'))\n",
    "        plt.close(fig)\n",
    "\n",
    "    # 結果の表示\n",
    "    print(result_df)\n",
    "\n",
    "    # 結果の保存\n",
    "    result_file_path = os.path.join(save_path, 'prediction_result.csv')\n",
    "    result_df.to_csv(result_file_path, index=False)\n",
    "\n",
    "def output(df:pd.DataFrame, models:dict):\n",
    "    \"\"\"\n",
    "    df, modelsを受け取り、予測モデルに基づいて目的変数の列を入力dfに新たに作成し、予測値を格納する。\n",
    "    Args:\n",
    "        df (pd.DataFrame): 入力データ。時間列と各列の計画値が入ったDataFrame\n",
    "        models (dict): 予測モデル、各列の値から各出力を予測するモデルが格納されたdict\n",
    "    Returns:\n",
    "        pd.DataFrame: 入力データに対する予測データを格納したDataFrame\n",
    "    \"\"\"\n",
    "    var_dict = pickle_load('/workspaces/data/control/optimization_mapping/var_dict.pkl')\n",
    "    df = one_hot_encode_hours(df)\n",
    "    result = {}\n",
    "\n",
    "    for target, model in models.items():\n",
    "        features = var_dict[target]\n",
    "        valid_columns = [col for col in features if col in df.columns]\n",
    "        result[target] = model.predict(df[valid_columns])\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "def check_file_path(file_path: str):\n",
    "    import os\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"No file found at {file_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 必要ファイルのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = pickle_load('/workspaces/data/control/optimization_mapping/var_dict.pkl')\n",
    "df = pd.read_pickle('/workspaces/data/flow/preprocessed_dataset.pkl')\n",
    "models = pickle_load('/workspaces/data/control/optimization_models/best_models_mae.pkl')\n",
    "columns = pickle_load('/workspaces/data/control/optimization_mapping/columns.pkl')\n",
    "columns_mapping = pickle_load('/workspaces/data/control/optimization_mapping/columns_mapping.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト用サンプルデータ作成用関数　基本的にはテストのみに使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用のサンプルデータを生成する関数\n",
    "def create_sample_data(total_hours, total_areas, num_constants):\n",
    "    # 変数のリストを生成\n",
    "    variables = np.random.randint(1, 10, total_hours * total_areas - num_constants)\n",
    "    \n",
    "    # 定数スケジュールを生成\n",
    "    constant_schedule = np.zeros((total_hours, total_areas))\n",
    "    constant_indices = np.random.choice(total_hours * total_areas, num_constants, replace=False)\n",
    "    constant_schedule.flat[constant_indices] = np.random.randint(1, 10, num_constants)\n",
    "    constant_schedule[0, 0] = np.nan  # テスト用に1つのNaNを含むように変更\n",
    "    constant_schedule[1, 1] = np.nan  # テスト用に1つのNaNを含むように変更\n",
    "    \n",
    "    return variables, constant_schedule\n",
    "\n",
    "vars, constant_schedule = create_sample_data(23, 6, 92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "total_hours = 23\n",
    "total_areas = 6\n",
    "total_products = 3\n",
    "total_vars = total_hours * total_areas + 4\n",
    "total_objects = 3\n",
    "total_contraints = 34\n",
    "worker_min = 0\n",
    "worker_max = 48\n",
    "csv_path = '/workspaces/data/control/optimization_mapping/constant_schedule.csv'\n",
    "\n",
    "def read_constant_schedule(csv_filepath: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    CSVファイルから定数スケジュールを読み込み、NumPy配列として返します。\n",
    "    Args:\n",
    "        csv_filepath (str): CSVファイルへのパス。\n",
    "    Returns:\n",
    "        np.array: 定数スケジュールのNumPy配列。\n",
    "    \"\"\"\n",
    "    check_file_path(csv_filepath)\n",
    "    df = pd.read_csv(csv_path, encoding='shift-jis')\n",
    "    df = df.rename(columns=columns_mapping)\n",
    "    df = df.filter(columns, axis=1)\n",
    "    constant_schedule = df.values\n",
    "    return constant_schedule\n",
    "\n",
    "def apply_constant_schedule(variables: list, constant_schedule: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    変数と定数スケジュールを組み合わせて、作業者のスケジュールを作成します。\n",
    "    Args:\n",
    "        variables (list): 最適化問題の変数のリスト。\n",
    "        constant_schedule (np.array): 定数スケジュールのNumPy配列。\n",
    "    Returns:\n",
    "        np.array: 作業者スケジュールのNumPy配列。\n",
    "    \"\"\"\n",
    "    constant_mask = np.logical_not(np.isnan(constant_schedule))\n",
    "    worker_schedule = np.zeros(constant_schedule.shape)\n",
    "    index = 0\n",
    "    for i in range(constant_schedule.shape[0]):\n",
    "        for j in range(constant_schedule.shape[1]):\n",
    "            if constant_mask[i, j]:\n",
    "                worker_schedule[i, j] = constant_schedule[i, j]\n",
    "            else:\n",
    "                worker_schedule[i, j] = variables[index]\n",
    "                index += 1\n",
    "    return worker_schedule\n",
    "\n",
    "def belegundu(vars: list) -> tuple:\n",
    "    \"\"\"\n",
    "    最適化問題の目的関数と制約条件を設定します。\n",
    "    Args:\n",
    "        vars (list): 最適化された変数のリスト。\n",
    "    Returns:\n",
    "        tuple: (目的関数のリスト, 制約条件のリスト)\n",
    "    \"\"\"\n",
    "    w1, w2, w3, w4 = np.array(vars[:4])\n",
    "    constant_schedule = read_constant_schedule('/workspaces/data/control/optimization_mapping/constant_schedule.csv')\n",
    "    worker_schedule = apply_constant_schedule(variables=vars, constant_schedule=constant_schedule)\n",
    "    df = pd.DataFrame(worker_schedule, columns=columns)\n",
    "    df['hour'] = [hour % 24 for hour in range(8, 31)]\n",
    "    \n",
    "    # Objective function\n",
    "    result = output(df, models)\n",
    "    production_a = result['1F']\n",
    "    production_c = result['3F']\n",
    "    total_worker = np.array(vars[:4]).sum()\n",
    "\n",
    "    objective_function = [-production_a.sum(), -production_c.sum(), total_worker]\n",
    "\n",
    "    # Constraint function\n",
    "    constraint1 = -production_a.sum() + 30000\n",
    "    constraints3to9 = [worker_schedule[i].sum() - get_schedule_limit(w1, w2, w3, w4, i) for i in range(total_hours)]\n",
    "    constraint10 = - 48 + (w1 + w2)\n",
    "    constraint11 = - 48 + (w2 + w3)\n",
    "    constraint12_1 = [-wi for wi in [w1, w2, w3, w4]]\n",
    "    constraint12_2 = [-48 + wi for wi in [w1, w2, w3, w4]]\n",
    "\n",
    "    constraint_function = [constraint1] + constraints3to9 + [constraint10, constraint11] + constraint12_1 + constraint12_2\n",
    "\n",
    "    return objective_function, constraint_function\n",
    "\n",
    "def get_schedule_limit(w1, w2, w3, w4, hour):\n",
    "    \"\"\"\n",
    "    指定された時間帯に対するスケジュール制限を計算します。\n",
    "    Args:\n",
    "        hour (int): 時間帯 (0-22)。\n",
    "        w1 (float): : 制約条件用の変数。\n",
    "    Returns:\n",
    "        float: 指定された時間帯に対するスケジュール制限。\n",
    "    \"\"\"\n",
    "    if hour == 0:\n",
    "        return 0.8 * w1\n",
    "    elif hour == 1:\n",
    "        return 0.8 * w2 + w1\n",
    "    elif 2 <= hour <= 8:\n",
    "        return w1 + w2\n",
    "    elif hour == 9:\n",
    "        return w2 + 0.5 * 0.8 * w3\n",
    "    elif 10 <= hour <= 13:\n",
    "        return w3\n",
    "    elif hour == 14:\n",
    "        return 0.8 * w4\n",
    "    else:\n",
    "        return w4\n",
    "\n",
    "constant_schedule = read_constant_schedule(csv_path)\n",
    "problem = Problem(4 + (total_hours * total_areas - np.count_nonzero(~np.isnan(constant_schedule))), total_objects, total_contraints)  # 変数の数, 目的関数の数, 制約条件の数\n",
    "problem.types[:] = [Real(worker_min, worker_max) for _ in range(4 + (total_hours * total_areas - np.count_nonzero(~np.isnan(constant_schedule))))]\n",
    "problem.constraints[:] = \"<=0\"\n",
    "problem.function = belegundu\n",
    "\n",
    "algorithm = NSGAIII(problem, divisions_outer=5)\n",
    "algorithm.run(30000)  # 試行\n",
    "\n",
    "# 解集合を取得\n",
    "solutions = algorithm.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraint_check(vars):\n",
    "    \"\"\"\n",
    "    与えられた変数に対して制約条件をチェックし、違反している制約の数を返す関数。\n",
    "    Args:\n",
    "        vars (list): 制約条件をチェックする変数のリスト。\n",
    "    Returns:\n",
    "        int: 違反している制約の数。\n",
    "    この関数は、次の手順で制約条件をチェックします。\n",
    "    1. constraint_function によって制約条件を計算する。\n",
    "    2. 計算された制約条件が正の場合、違反していると判断し、フラグを立てる。\n",
    "    3. 違反している制約の数をカウントし、結果を返す。\n",
    "    \"\"\"\n",
    "    constraint_function = constraint_function(vars)\n",
    "    constraint_num = [f'constraint_{i}' for i in range(34)]\n",
    "    constrain_flag = [1 if constraint > 0 else 0 for constraint in constraint_function]\n",
    "\n",
    "    result = pd.DataFrame({\n",
    "        'number': constraint_num,\n",
    "        'flag':constrain_flag\n",
    "    })\n",
    "\n",
    "    return sum([1 if i > 0 else 0 for i in constraint_function])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_solution(vars):\n",
    "    \"\"\"\n",
    "    与えられた変数に対して制約条件をチェックし、違反している制約の数を返す関数。\n",
    "    Args:\n",
    "        vars (list): 制約条件をチェックする変数のリスト。\n",
    "    Returns:\n",
    "        int: 違反している制約の数。\n",
    "    この関数は、次の手順で制約条件をチェックします。\n",
    "    1. constraint_function によって制約条件を計算する。\n",
    "    2. 計算された制約条件が正の場合、違反していると判断し、フラグを立てる。\n",
    "    3. 違反している制約の数をカウントし、結果を返す。\n",
    "    \"\"\"\n",
    "    constraint_function = constraint_function(vars)\n",
    "    constraint_num = [f'constraint_{i}' for i in range(34)]\n",
    "    constrain_flag = [1 if constraint > 0 else 0 for constraint in constraint_function]\n",
    "\n",
    "    result = pd.DataFrame({\n",
    "        'number': constraint_num,\n",
    "        'flag':constrain_flag\n",
    "    })\n",
    "\n",
    "    return sum([1 if i > 0 else 0 for i in constraint_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2, w3, w4 = np.array(solutions[10].variables[:4])\n",
    "worker_schedule = np.array(solutions[10].variables[4:]).reshape(23, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions_value = []\n",
    "for i, solution in enumerate(solutions):\n",
    "    objective_values = solution.objectives\n",
    "    for j, obj_value in enumerate(objective_values):\n",
    "        if obj_value < 0:\n",
    "            obj_value = -1 * obj_value\n",
    "        objective_values[j] = obj_value\n",
    "    solutions_value.append(objective_values)\n",
    "solutions_df = pd.DataFrame(np.array(solutions_value), columns=['1F', '3F', 'eficiency', 'total_mh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions_df[solutions_df['eficiency'] == solutions_df['eficiency'].max()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
